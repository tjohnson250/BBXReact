% Constraint Satisfaction and LLMs

@inproceedings{bonlarron2024gencp,
  title={Combining Constraint Programming Reasoning with Large Language Model Predictions},
  author={Bonlarron, Alexandre and R{\'e}gin, Jean-Charles and De Maria, Elisabetta},
  booktitle={Proceedings of the 30th International Conference on Principles and Practice of Constraint Programming (CP 2024)},
  series={LIPIcs},
  volume={307},
  pages={25},
  year={2024},
  publisher={Schloss Dagstuhl},
  doi={10.4230/LIPIcs.CP.2024.25}
}

@inproceedings{michailidis2024constraint,
  title={Constraint Modelling with LLMs Using In-Context Learning},
  author={Michailidis, Kostis and Tsouros, Dimosthenis and Guns, Tias},
  booktitle={Proceedings of the 30th International Conference on Principles and Practice of Constraint Programming (CP 2024)},
  series={LIPIcs},
  volume={307},
  pages={20},
  year={2024},
  publisher={Schloss Dagstuhl},
  doi={10.4230/LIPIcs.CP.2024.20}
}

@article{lin2024zebralogic,
  title={ZebraLogic: Benchmarking the Logical Reasoning Ability of Language Models},
  author={Lin, Bill Yuchen and others},
  journal={Hugging Face Blog},
  year={2024},
  url={https://huggingface.co/blog/yuchenlin/zebra-logic}
}

@inproceedings{feger2024exploiting,
  title={Exploiting Large Language Models for the Automated Generation of Constraint Satisfaction Problem Solutions},
  author={Feger, Alexander and Felfernig, Alexander and others},
  booktitle={CEUR Workshop Proceedings},
  volume={3812},
  year={2024}
}

@article{freuder2024conversational,
  title={Conversational Modeling for Constraint Satisfaction},
  author={Freuder, Eugene C.},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={20},
  pages={22592--22597},
  year={2024},
  doi={10.1609/aaai.v38i20.30225}
}

% Spatial Reasoning

@inproceedings{tikhonov2024plugh,
  title={PLUGH: A Benchmark for Spatial Understanding and Reasoning in Large Language Models},
  author={Tikhonov, Alexey and others},
  booktitle={arXiv preprint},
  year={2024},
  eprint={2408.04648},
  archivePrefix={arXiv}
}

@article{chen2024spatial,
  title={An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models},
  author={Chen, Fangru and others},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={1195},
  year={2024}
}

@inproceedings{chen2024spatialvlm,
  title={SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities},
  author={Chen, Boyuan and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@inproceedings{mirzaee2024ppnl,
  title={Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-Temporal Reasoning},
  author={Mirzaee, Roshanak and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}

@article{xu2024stbench,
  title={Evaluating Large Language Models on Spatial Tasks: A Multi-Task Benchmarking Study},
  author={Xu, Liuchang and others},
  journal={arXiv preprint arXiv:2408.14438},
  year={2024}
}

@article{quan2025stark,
  title={Benchmarking Spatiotemporal Reasoning in LLMs and Reasoning Models: Capabilities and Challenges},
  author={Quan, Yida and others},
  journal={arXiv preprint arXiv:2505.11618},
  year={2025}
}

@article{bos2024spatial,
  title={Language Models and Spatial Reasoning: What's Good, What Is Still Terrible, and What Is Improving},
  author={Bos, Nathan},
  journal={Towards Data Science},
  year={2024},
  url={https://medium.com/data-science/language-models-and-spatial-reasoning}
}

% Reasoning Complexity and Scaling

@article{shojaee2025illusion,
  title={The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity},
  author={Shojaee, Parshin and Mirzadeh, Iman and Alizadeh, Keivan and Horton, Maxwell and Bengio, Samy and Farajtabar, Mehrdad},
  journal={arXiv preprint arXiv:2506.06941},
  year={2025}
}

% World Models and Mental Simulation

@article{harig2025worldmodels,
  title={LLM World Models are Mental: Output Layer Evidence of Brittle World Model Use in LLM Mechanical Reasoning},
  author={Harig, Tobin and others},
  journal={arXiv preprint arXiv:2507.15521},
  year={2025}
}

@inproceedings{wang2024bytesized,
  title={Can Language Models Serve as Text-Based World Simulators?},
  author={Wang, Ruoyao and Todd, Graham and Yuan, Xingdi and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics},
  year={2024}
}

@article{lewis2024counterfactual,
  title={Counterfactual Reasoning and Out-of-Distribution Performance in Large Language Models},
  author={Lewis, Martha and Mitchell, Melanie},
  journal={arXiv preprint},
  year={2024}
}

% Base Rate Neglect and Diagnostic Reasoning

@article{omar2025zebras,
  title={Large Language Models Chase Zebras: Salient Cues Overrule Base Rates in Clinical Diagnosis},
  author={Omar, Mahmud and Agbareia, Reem and Gorenshtein, Alon and Charney, Alexander W and Glicksberg, Benjamin S and Nadkarni, Girish N and Klang, Eyal},
  journal={SSRN preprint},
  year={2025},
  note={Preprint available at https://ssrn.com/abstract=5988435}
}

% Abductive Reasoning and Hypothesis Generation

@article{yang2025survey,
  title={From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models},
  author={Yang, Yunfan and others},
  journal={arXiv preprint arXiv:2505.21935},
  year={2025}
}

@article{liu2024incomplete,
  title={An Incomplete Loop: Deductive, Inductive, and Abductive Learning in Large Language Models},
  author={Liu, Emmy and Neubig, Graham and Andreas, Jacob},
  journal={arXiv preprint arXiv:2404.03028},
  year={2024}
}

@article{wang2025occam,
  title={Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning},
  author={Wang, Zonglin and others},
  journal={arXiv preprint arXiv:2509.03345},
  year={2025}
}

@inproceedings{pareschi2023abductive,
  title={Abductive Reasoning with the GPT-4 Language Model: An Investigation in Medical Diagnostics, Criminology, and Cosmology},
  author={Pareschi, Remo},
  booktitle={arXiv preprint arXiv:2307.10250},
  year={2023}
}

@article{rodriguez2025analogical,
  title={Analogical Mappings of Facts and Counterfactuals in the Human Mind and Peirce's Abduction: Limitations in LLMs},
  author={Rodriguez, Pablo and others},
  journal={Cognitive Systems Research},
  year={2025},
  doi={10.1016/j.cogsys.2025.101389}
}

% Scientific Discovery and LLMs

@article{preprints2025scaling,
  title={Beyond Scaling Laws: Towards Scientific Reasoning-Driven LLM Architectures},
  author={Various Authors},
  journal={Preprints.org},
  year={2025},
  doi={10.20944/preprints202504.2088}
}

@article{liang2025hypothesis,
  title={A Survey on Hypothesis Generation for Scientific Discovery in the Era of Large Language Models},
  author={Liang, Chen and others},
  journal={arXiv preprint arXiv:2504.05496},
  year={2025}
}

% Human Simulation and LLM Limitations

@article{wang2025limits,
  title={What Limits LLM-based Human Simulation: LLMs or Our Design?},
  author={Wang, Qian and Wu, Jiaying and others},
  journal={arXiv preprint arXiv:2501.08579},
  year={2025}
}

@article{chen2025chatgpt,
  title={From ChatGPT to DeepSeek: Can LLMs Simulate Humanity?},
  author={Chen, Yu and others},
  journal={arXiv preprint arXiv:2502.18210},
  year={2025}
}

% Classical AI and Cognitive Science References

@book{newell1990unified,
  title={Unified Theories of Cognition},
  author={Newell, Allen},
  year={1990},
  publisher={Harvard University Press}
}

@article{anderson2004integrated,
  title={An Integrated Theory of the Mind},
  author={Anderson, John R. and Bothell, Daniel and Byrne, Michael D. and Douglass, Scott and Lebiere, Christian and Qin, Yulin},
  journal={Psychological Review},
  volume={111},
  number={4},
  pages={1036--1060},
  year={2004},
  doi={10.1037/0033-295X.111.4.1036}
}

@article{kambhampati2024llmmodulo,
  title={LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks},
  author={Kambhampati, Subbarao and others},
  journal={arXiv preprint arXiv:2402.01817},
  year={2024}
}

@article{valmeekam2023planning,
  title={On the Planning Abilities of Large Language Models: A Critical Investigation},
  author={Valmeekam, Karthik and Marquez, Matthew and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

% Black Box Game

@misc{blackbox1978,
  title={Black Box (game)},
  author={{Wikipedia contributors}},
  year={2024},
  howpublished={\url{https://en.wikipedia.org/wiki/Black_Box_(game)}},
  note={Board game designed by Eric Solomon, 1978}
}

% General LLM Capabilities and Limitations

@article{wei2022chain,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{bubeck2023sparks,
  title={Sparks of Artificial General Intelligence: Early Experiments with GPT-4},
  author={Bubeck, S{\'e}bastien and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@article{marcus2020next,
  title={The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence},
  author={Marcus, Gary},
  journal={arXiv preprint arXiv:2002.06177},
  year={2020}
}

@article{willison2024llms,
  title={Things We Learned About LLMs in 2024},
  author={Willison, Simon},
  journal={Simon Willison's Weblog},
  year={2024},
  url={https://simonwillison.net/2024/Dec/31/llms-in-2024/}
}
